#!/usr/bin/env python3
"""
Redis Caching Service for eaiser API

This service provides high-performance caching capabilities to reduce database load
and improve API response times, especially for frequently accessed data like issues list.

Features:
- Automatic cache invalidation
- Configurable TTL (Time To Live)
- JSON serialization/deserialization
- Connection pooling
- Error handling with fallback to database
- Production-ready configuration for Render deployment
"""

import json
import logging
import asyncio
from typing import Any, Optional, List, Dict
from datetime import datetime, timedelta
import redis.asyncio as redis
from redis.asyncio import ConnectionPool
import os
from dotenv import load_dotenv
from urllib.parse import urlparse

# Load environment variables
load_dotenv()

# Setup logging
logger = logging.getLogger(__name__)

def get_redis_config():
    """
    Get Redis configuration with production-ready settings for Render deployment.
    
    Returns:
        tuple: (host, port, password, db, ssl_required)
    """
    # Priority order for Redis configuration
    # 1. REDIS_URL (full connection string) - preferred for production
    # 2. Individual environment variables
    # 3. Localhost fallback for development
    
    redis_url = os.getenv('REDIS_URL')
    
    if redis_url:
        # Fix malformed URLs (missing scheme) commonly found in dev environments
        if not redis_url.startswith(('redis://', 'rediss://', 'unix://')):
             redis_url = f"redis://{redis_url}"

        # Parse Redis URL format: redis://[:password@]host:port[/db]
        # or rediss://[:password@]host:port[/db] for SSL
        try:
            parsed = urlparse(redis_url)
            
            host = parsed.hostname or 'localhost'
            port = parsed.port or 6379
            password = parsed.password
            db = int(parsed.path[1:]) if parsed.path and len(parsed.path) > 1 else 0
            ssl_required = parsed.scheme == 'rediss'
            
            logger.info(f"üîß Redis URL configured: {parsed.scheme}://{host}:{port}/{db}")
            return host, port, password, db, ssl_required
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to parse REDIS_URL: {e}")
    
    # Fallback to individual environment variables
    host = os.getenv('REDIS_HOST', 'localhost')
    port = int(os.getenv('REDIS_PORT', 6379))
    password = os.getenv('REDIS_PASSWORD', None)
    db = int(os.getenv('REDIS_DB', 0))
    ssl_required = os.getenv('REDIS_SSL', 'false').lower() == 'true'
    
    # Log configuration (hide sensitive info)
    password_display = "***" if password else "None"
    logger.info(f"üîß Redis Configuration:")
    logger.info(f"   Host: {host}")
    logger.info(f"   Port: {port}")
    logger.info(f"   Password: {password_display}")
    logger.info(f"   Database: {db}")
    logger.info(f"   SSL: {ssl_required}")
    logger.info(f"   Environment: {'Production' if host != 'localhost' else 'Development'}")
    
    return host, port, password, db, ssl_required

class RedisService:
    """
    High-performance Redis caching service with automatic failover.
    """
    
    def __init__(self):
        self.redis_client: Optional[redis.Redis] = None
        self.connection_pool: Optional[ConnectionPool] = None
        self.is_connected = False
        
        # Cache configuration
        self.default_ttl = 300  # 5 minutes default TTL
        self.issues_cache_ttl = 180  # 3 minutes for issues list
        self.health_cache_ttl = 60   # 1 minute for health checks
        
        # Get Redis configuration
        self.redis_host, self.redis_port, self.redis_password, self.redis_db, self.ssl_required = get_redis_config()

    async def connect(self) -> bool:
        """
        Establish connection to Redis server with connection pooling.
        Production-ready configuration with SSL support and graceful fallback.
        
        Returns:
            bool: True if connection successful, False otherwise
        """
        try:
            # üü¢ Guard: Check REDIS_URL validity strictly
            redis_url = os.getenv('REDIS_URL')
            
            # Smart Logic: Construct URL if missing but host/port exist (Legacy/Dev)
            if not redis_url:
                if self.redis_host and self.redis_host != 'localhost':
                     if self.redis_password:
                        redis_url = f"redis://:{self.redis_password}@{self.redis_host}:{self.redis_port}/{self.redis_db}"
                     else:
                        redis_url = f"redis://{self.redis_host}:{self.redis_port}/{self.redis_db}"
                elif self.redis_host == 'localhost':
                     logger.info("‚ö†Ô∏è No REDIS_URL set. Using localhost (Development Logic).")
                     redis_url = "redis://localhost:6379/0"

            # üü¢ Guard Clause requested by User
            if not redis_url or not redis_url.startswith(("redis://", "rediss://", "unix://")):
                if redis_url and not redis_url.startswith(("redis://", "rediss://", "unix://")):
                     # Try to auto-fix simple host:port strings
                     logger.warning(f"‚ö†Ô∏è Malformed REDIS_URL detected. Auto-fixing to 'redis://{redis_url}'")
                     redis_url = f"redis://{redis_url}"
                else:
                    logger.warning("‚ö†Ô∏è Invalid or Missing REDIS_URL. Redis disabled.")
                    self.is_connected = False
                    return False

            # Use ConnectionPool.from_url to let the client handle ssl/rediss scheme internally
            pool_kwargs = {
                'decode_responses': True,
                'max_connections': 20,
                'retry_on_timeout': True,
                'socket_connect_timeout': 5, # Fast fail as requested
                'socket_timeout': 5,
                'health_check_interval': 30,
            }
            
            # If using rediss (TLS), relax cert checks for managed services without CA bundles
            try:
                parsed = urlparse(redis_url)
                if parsed.scheme == 'rediss':
                    pool_kwargs['ssl_cert_reqs'] = None
                    pool_kwargs['ssl_check_hostname'] = False
                    logger.info("üîí TLS (rediss) detected; cert verification disabled for managed Redis")
            except Exception:
                pass

            self.connection_pool = ConnectionPool.from_url(redis_url, **pool_kwargs)
            self.redis_client = redis.Redis(connection_pool=self.connection_pool)
            
            # Test connection with timeout
            await asyncio.wait_for(self.redis_client.ping(), timeout=5.0)
            self.is_connected = True
            
            logger.info("‚úÖ Redis connected successfully")
            return True
            
        except asyncio.TimeoutError:
            logger.warning(f"‚è∞ Redis connection timeout")
            self.is_connected = False
            return False
        except ConnectionRefusedError:
            logger.warning(f"üö´ Redis connection refused")
            self.is_connected = False
            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis connection failed: {str(e)}")
            self.is_connected = False
            return False
    
    async def disconnect(self):
        """
        Gracefully close Redis connection.
        """
        try:
            if self.redis_client:
                await self.redis_client.close()
            if self.connection_pool:
                await self.connection_pool.disconnect()
            self.is_connected = False
            logger.info("üîå Redis connection closed")
        except Exception as e:
            logger.error(f"‚ùå Error closing Redis connection: {str(e)}")
    
    def _serialize_data(self, data: Any) -> str:
        """
        Serialize data to JSON string for Redis storage.
        
        Args:
            data: Data to serialize
            
        Returns:
            str: JSON string
        """
        try:
            # Handle datetime objects
            def json_serializer(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
            
            return json.dumps(data, default=json_serializer, ensure_ascii=False)
        except Exception as e:
            logger.error(f"‚ùå Serialization error: {str(e)}")
            raise
    
    def _deserialize_data(self, data: str) -> Any:
        """
        Deserialize JSON string from Redis.
        
        Args:
            data: JSON string from Redis
            
        Returns:
            Any: Deserialized data
        """
        try:
            return json.loads(data)
        except Exception as e:
            logger.error(f"‚ùå Deserialization error: {str(e)}")
            raise
    
    async def get(self, key: str) -> Optional[Any]:
        """
        Get data from Redis cache.
        
        Args:
            key: Cache key
            
        Returns:
            Optional[Any]: Cached data or None if not found/error
        """
        if not self.is_connected or not self.redis_client:
            return None
        
        try:
            cached_data = await self.redis_client.get(key)
            if cached_data:
                logger.debug(f"üéØ Cache HIT for key: {key}")
                return self._deserialize_data(cached_data)
            else:
                logger.debug(f"‚ùå Cache MISS for key: {key}")
                return None
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis GET error for key {key}: {str(e)}")
            return None
    
    async def set(self, key: str, data: Any, ttl: Optional[int] = None) -> bool:
        """
        Set data in Redis cache with TTL.
        
        Args:
            key: Cache key
            data: Data to cache
            ttl: Time to live in seconds (optional)
            
        Returns:
            bool: True if successful, False otherwise
        """
        if not self.is_connected or not self.redis_client:
            return False
        
        try:
            serialized_data = self._serialize_data(data)
            ttl = ttl or self.default_ttl
            
            await self.redis_client.setex(key, ttl, serialized_data)
            logger.debug(f"üíæ Cache SET for key: {key} (TTL: {ttl}s)")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis SET error for key {key}: {str(e)}")
            return False
    
    async def delete(self, key: str) -> bool:
        """
        Delete data from Redis cache.
        
        Args:
            key: Cache key to delete
            
        Returns:
            bool: True if successful, False otherwise
        """
        if not self.is_connected or not self.redis_client:
            return False
        
        try:
            result = await self.redis_client.delete(key)
            logger.debug(f"üóëÔ∏è Cache DELETE for key: {key}")
            return bool(result)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis DELETE error for key {key}: {str(e)}")
            return False
    
    async def invalidate_pattern(self, pattern: str) -> int:
        """
        Invalidate all cache keys matching a pattern.
        
        Args:
            pattern: Redis key pattern (e.g., "issues:*")
            
        Returns:
            int: Number of keys deleted
        """
        if not self.is_connected or not self.redis_client:
            return 0
        
        try:
            keys = await self.redis_client.keys(pattern)
            if keys:
                deleted = await self.redis_client.delete(*keys)
                logger.info(f"üßπ Cache invalidated {deleted} keys matching pattern: {pattern}")
                return deleted
            return 0
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis pattern invalidation error for {pattern}: {str(e)}")
            return 0
    
    # Specialized cache methods for eaiser API
    
    async def cache_issues_list(self, issues: List[Dict], limit: int, skip: int) -> bool:
        """
        Cache issues list with pagination parameters.
        
        Args:
            issues: List of issues to cache
            limit: Pagination limit
            skip: Pagination skip
            
        Returns:
            bool: True if cached successfully
        """
        cache_key = f"issues:list:{limit}:{skip}"
        return await self.set(cache_key, issues, self.issues_cache_ttl)
    
    async def get_cached_issues_list(self, limit: int, skip: int) -> Optional[List[Dict]]:
        """
        Get cached issues list with pagination parameters.
        
        Args:
            limit: Pagination limit
            skip: Pagination skip
            
        Returns:
            Optional[List[Dict]]: Cached issues or None
        """
        cache_key = f"issues:list:{limit}:{skip}"
        return await self.get(cache_key)
    
    async def invalidate_issues_cache(self) -> int:
        """
        Invalidate all issues-related cache entries.
        
        Returns:
            int: Number of cache entries invalidated
        """
        return await self.invalidate_pattern("issues:*")
    
    async def cache_health_status(self, status: Dict) -> bool:
        """
        Cache health check status.
        
        Args:
            status: Health status data
            
        Returns:
            bool: True if cached successfully
        """
        return await self.set("health:status", status, self.health_cache_ttl)
    
    async def get_cached_health_status(self) -> Optional[Dict]:
        """
        Get cached health check status.
        
        Returns:
            Optional[Dict]: Cached health status or None
        """
        return await self.get("health:status")
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """
        Get Redis cache statistics.
        
        Returns:
            Dict[str, Any]: Cache statistics
        """
        if not self.is_connected or not self.redis_client:
            return {"status": "disconnected", "keys": 0}
        
        try:
            info = await self.redis_client.info()
            keys_count = await self.redis_client.dbsize()
            
            return {
                "status": "connected",
                "keys": keys_count,
                "memory_used": info.get('used_memory_human', 'N/A'),
                "connected_clients": info.get('connected_clients', 0),
                "total_commands_processed": info.get('total_commands_processed', 0),
                "keyspace_hits": info.get('keyspace_hits', 0),
                "keyspace_misses": info.get('keyspace_misses', 0)
            }
        except Exception as e:
            logger.error(f"‚ùå Error getting cache stats: {str(e)}")
            return {"status": "error", "error": str(e)}

# Global Redis service instance
redis_service = RedisService()

# Convenience functions for easy import
async def get_redis_service() -> RedisService:
    """
    Get the global Redis service instance.
    
    Returns:
        RedisService: Global Redis service instance
    """
    if not redis_service.is_connected:
        await redis_service.connect()
    return redis_service

async def init_redis():
    """
    Initialize Redis service with graceful error handling.
    Application will continue to work even if Redis is unavailable.
    """
    try:
        success = await redis_service.connect()
        if not success:
             # Logic is handled inside connect logs
             pass
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Redis initialization failed: {str(e)} - continuing without caching")

async def close_redis():
    """
    Gracefully close Redis connection.
    """
    try:
        await redis_service.disconnect()
    except Exception as e:
        logger.error(f"‚ùå Error closing Redis: {str(e)}")